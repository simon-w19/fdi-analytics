# üìö Vollst√§ndiger Leitfaden durch alle Notebooks

## √úberblick: Die Data-Science-Pipeline

Dieses Projekt folgt einer **Standard-Data-Science-Pipeline** mit vier Hauptphasen:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. EXPLORATIVE DATENANALYSE (EDA)  ‚Üí eda.ipynb            ‚îÇ
‚îÇ     "Verstehen wir die Daten?"                             ‚îÇ
‚îÇ                          ‚Üì                                  ‚îÇ
‚îÇ  2. FEATURE ENGINEERING & PREPROCESSING ‚Üí fdi_rating_modeling.ipynb (Teil 1)
‚îÇ     "Welche neuen Features erstellen wir?"                ‚îÇ
‚îÇ                          ‚Üì                                  ‚îÇ
‚îÇ  3. MODELLTRAINING & VERGLEICH ‚Üí fdi_rating_modeling.ipynb (Teil 2)
‚îÇ     "Welches Modell funktioniert am besten?"              ‚îÇ
‚îÇ                          ‚Üì                                  ‚îÇ
‚îÇ  4. EVALUATION & DIAGNOSE ‚Üí fdi_rating_modeling.ipynb (Teil 3)
‚îÇ     "Warum funktioniert es? Fehler verstehen?"            ‚îÇ
‚îÇ                          ‚Üì                                  ‚îÇ
‚îÇ  5. DOKUMENTATION ‚Üí report.ipynb + slides.md              ‚îÇ
‚îÇ     "Ergebnisse kommunizieren"                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 1Ô∏è‚É£ NOTEBOOK: `notebooks/eda.ipynb`
### Explorative Datenanalyse

**Ziel:** Die Rohdaten verstehen, Muster entdecken, Anomalien identifizieren.

**Methodologie:** Wir folgen dem **OpenIntro-Prinzip** (Introduction to Modern Statistics):
- Univariate Analyse (eine Variable allein)
- Bivariate Analyse (zwei Variablen zusammen)
- Multivariate Muster (Gruppen und Interaktionen)

---

### üîç Abschnitt 1: Datenstruktur & Messniveaus

**WAS:** Klassifikation aller 34 Variablen nach Typ (numerisch/kategorisch) und Messniveau.

**WIE:**
```python
# Jede Spalte wird untersucht:
for col in df.columns:
    dtype = df[col].dtype  # int64, float64, object?
    unique_count = df[col].nunique()  # Wieviele verschiedene Werte?
    missing_pct = df[col].isna().mean() * 100  # % fehlende Werte?
    
    if is_bool_dtype(col):
        measurement = "binary"  # Ja/Nein
    elif is_numeric_dtype(col) and unique_count > 10:
        measurement = "interval"  # Kontinuierliche Zahlen
    else:
        measurement = "nominal"  # Kategorien ohne Ordnung
```

**WARUM:** 
- Messniveaus bestimmen, welche Statistik sinnvoll ist
- Fehlende Werte m√ºssen adressiert werden (Imputation)
- Kategorische Variablen brauchen One-Hot-Encoding

**OUTPUT-INTERPRETATION:**
| Feature | Type | Messniveau | Missing% | Bedeutung |
|---------|------|-----------|----------|-----------|
| profile_fdi_rating | float64 | interval | 0% | Zielvarinale - keine NaNs ‚úÖ |
| age | float64 | interval | ~5% | Braucht Imputation |
| country | object | nominal | <1% | Kategorisch, ~30 L√§nder |

---

### üìä Abschnitt 2: Univariate Verteilungen

**WAS:** Histogramme + Dichte-Kurven f√ºr 6 Kern-Variablen:
- `profile_fdi_rating` (unser Ziel)
- `last_12_months_averages` (Durchschnitt)
- `last_12_months_first_9_averages` (Early-Game-Durchschnitt)
- `last_12_months_checkout_pct` (Checkout-Erfolg)
- `last_12_months_functional_doubles_pct` (Double-Erfolg)
- `last_12_months_pct_legs_won` (Gewinnrate)

**WARUM:**
- Normalverteilung? ‚Üí Linear Regression funktioniert besser
- Schiefe Verteilung? ‚Üí Log-Transformation oder robuste Modelle n√∂tig
- Ausrei√üer sichtbar? ‚Üí Data Cleaning n√∂tig

**INTERPRETATION:**

| Variable | Form | Interpretation |
|----------|------|---|
| FDI Rating | ‚à© (glockenf√∂rmig) | Normalverteilt! Linear Regression sollte funktionieren ‚úÖ |
| Averages | ‚à© leicht links-schief | Normal mit Schwanz nach Links (schwache Spieler existieren) |
| Checkout% | Breite Streuung | Spieler haben sehr unterschiedliche Checkout-Skills |
| Legs Won % | Links-schief | Viele Spieler ~60% Win-Rate, wenige bei 20-30% |
| Log-Earnings | Stark rechts-schief! | BRAUCHT Log-Transform um normalverteilt zu sein |

**KEY-INSIGHT:** Most metrics sind annehmbar normalverteilt ‚Üí Lineare Modelle sind reasonable choice.

---

### üîó Abschnitt 3: Korrelationsmatrix

**WAS:** Eine 13√ó13 Heatmap zeigt Pearson-Korrelationen zwischen allen Hauptvariablen.

**KORRELATION r:**
- r = 1: Perfekt positiv (wenn A steigt, steigt B auch)
- r = 0: Keine Beziehung
- r = -1: Perfekt negativ

**FARBCODIERUNG:**
```
Rot (r > 0.7)    = Starke positive Korrelation ‚ö†Ô∏è
Orange (r >0.5)  = Moderate positive Korrelation ‚ö†Ô∏è
Blau (r < 0.5)   = Schwache Korrelation ‚úÖ
```

**HAUPTFINDINGS:**

1. **Mit FDI-Rating (Oberste Zeile):**
   ```
   r = 0.95 mit last_12_months_averages        ‚Üí Strongest single predictor!
   r = 0.95 mit last_12_months_first_9_averages ‚Üí Almost as strong
   r = 0.88 mit last_12_months_checkout_pct    ‚Üí Strong, but weaker
   r = 0.95 mit api_overall_stat               ‚Üí SUSPICIOUS! (r=1.0 = perfect!)
   ```
   **Interpretation:** Recent performance (last 12 months) ist der beste Indikator f√ºr FDI-Rating.

2. **Multikollinearit√§t entdeckt (Gro√üe rote Zellen √ºberall):**
   ```
   r = 0.99 zwischen last_12_months_averages ‚Üî last_12_months_first_9_averages
   r = 0.99 zwischen checkout_pct ‚Üî functional_doubles_pct
   r = 0.93 zwischen functional_doubles_pct ‚Üî checkout_pct
   ```
   **Interpretation:** Features sind untereinander stark abh√§ngig! 
   ‚Üí Einzeln starke Pr√§diktoren, aber zusammen problematisch (Multikollinearit√§t).
   ‚Üí Sp√§ter mit Regularisierung (Ridge/Lasso) adressieren.

---

### üìç Abschnitt 4: Geografische Muster (Ridge Plots)

**WAS:** Kernel-Dichte-Plots der FDI-Verteilung f√ºr Top-6 L√§nder √ºberlagert.

**INTERPRETATION:**

```
FDI Rating
2000 ‚îÇ     ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
     ‚îÇ    ‚ï≠‚îÇ (NED) ‚îÇ‚ïÆ
     ‚îÇ   ‚ï≠‚îÇ (ENG)  ‚îÇ‚îÇ‚ïÆ
1500 ‚îÇ  ‚ï≠‚îÇ        ‚îÇ‚îÇ‚îÇ‚ïÆ
     ‚îÇ ‚ï≠‚îÇ         ‚îÇ‚îÇ‚îÇ
1000 ‚îÇ ‚îÇ          ‚îÇ‚îÇ‚îÇ  ‚Üê UNK (Unknown) Spieler sind hier!
     ‚îÇ ‚îÇ          ‚îÇ‚îÇ
 500 ‚îÇ ‚îÇ          ‚îÇ
     ‚îî‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚î¥‚îÄ‚îÄ‚îÄ‚îÄ
```

**KERN-BEFUNDE:**

| Land | Position | Interpretation |
|------|----------|---|
| ENG (England) | Nach RECHTS verschoben | H√∂chste durchschn. FDI (~1400) |
| NED (Niederlande) | √Ñhnlich ENG | H√∂chste durchschn. FDI (~1350) |
| GER (Deutschland) | Nach LINKS! | Niedrigere FDI (~1200) |
| AUS (Australien) | Mittelm√§√üig | ~1300 durchschn. |
| UNK (Unbekannt) | WEIT LINKS! | Sehr niedrig (~1050) |

**BUSINESS-INSIGHT:** 
"Elite-Darts-Nationen" (ENG, NED) haben deutlich h√∂here durchschnittliche Spielerst√§rke. Das ist **nicht zuf√§llig**, sondern ein echte geografischer Effekt. M√∂gliche Ursachen:
- Darts-Kultur & Training in UK/Niederlande st√§rker
- Selektionsbias: Nur die Besten verlassen UK/NED zum Spielen
- Dataset-Sampling: Vielleicht wurden UK/NED-Spieler gezielt gesammelted

**MODELLIERUNGS-KONSEQUENZ:** Land-Dummies m√ºssen ins Modell!

---

### üîÄ Abschnitt 5: Faceting (Simpson's Paradox Check)

**WAS:** Die Beziehung zwischen zwei Features (FDI vs. First-9-Average) wird **getrennt nach Land** geplottet.

**WARUM:** Test auf **Simpson's Paradox** - ein statistisches Ph√§nomen, bei dem ein Trend in gesamten Daten sich in Untergruppen umkehrt.

**BEISPIEL Simpson's Paradox:**
```
Gesamt-Trend: "Bessere Spieler verdienen mehr"
Aber wenn wir nach Jahr aufsplittet:
  - 2020: "Bessere Spieler verdienen WENIGER" (weil 2020 weniger Geld da)
  - 2021: "Bessere Spieler verdienen WENIGER" (weil 2021 andere Turniere)
```

**UNSERER BEFUND:** 
```
Alle 4 L√§nder (ENG, NED, GER, UNK) zeigen 
die gleiche Beziehung: H√∂here First-9-Average ‚Üí H√∂heres FDI
Keine Umkehr! ‚úÖ
```

**INTERPRETATION:**
The relationship is **robust and universal** - es ist nicht confounded durch Land-Effekte. Diese Variable wird in allen L√§ndern gleich gut funktionieren.

---

### üé≤ Abschnitt 6: Kontingenztabellen & Chi-Quadrat-Tests

**WAS:** Kreuztabellen zwischen **kategorischen Variablen** (Land √ó FDI-Kategorie).

**TEST 1: Land √ó FDI Top-Quartil (Ist ein Land √ºberrepr√§sentiert in Top 25%?)**

```
                 Top 25%  Rest 75%  | Total | % in Top25%
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
England (ENG)        90       159  |  249  |  36.1% ‚Üê Over-repr√§sentiert!
Niederlande (NED)    65       120  |  185  |  35.1% ‚Üê Over-repr√§sentiert!
Australien (AUS)     42       140  |  182  |  23.1% ‚Üê Unter-repr√§sentiert
Deutschland (GER)    25       115  |  140  |  17.9% ‚Üê Stark unter-repr√§sentiert!
Unbekannt (UNK)      15       156  |  171  |   8.8% ‚Üê Extrem unter-repr√§sentiert!
```

**Chi-Quadrat-Test Ergebnis:**
```
œá¬≤ = 134.17
p-value = 0.0000 (< 0.0001)
DoF = 7
```

**INTERPRETATION:**
- œá¬≤ = 134 ist SEHR GROss (bei DoF=7, kritischer Wert ~12)
- p-value < 0.0001 ‚Üí **Extrem signifikant**
- **Konklusion:** L√§nder und FDI-Erfolg sind DEFINITIV nicht unabh√§ngig!
- **Effekt-Gr√∂√üe:** Riesig. England/Niederlande sind wirklich besser.

---

**TEST 2: Land √ó Checkout-Performance (4 Buckets)**

```
                Low     Medium  High   VeryHigh | œá¬≤ Test
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
England         20%     25%     30%    25%
Niederlande     18%     24%     32%    26%
Australien      30%     30%     28%    12%  ‚Üê Weniger High/VeryHigh
Deutschland     40%     30%     20%    10%  ‚Üê Deutlich schw√§cher
Unbekannt       45%     35%     15%     5%  ‚Üê Am schw√§chsten

œá¬≤ = 407.19 (!!!)
p-value = 0.0000
```

**INTERPRETATION:**
- œá¬≤ = 407 ist *gigantisch* (noch gr√∂√üer als Test 1)
- **Checkout-Skill differenziert L√§nder EXTREM stark**
- England/Niederlande haben deutlich h√∂here High/VeryHigh Checkout-Quoten
- Deutschland und Unknown L√§nder sind viel schw√§cher

**GESAMTFAZIT EDA:**
‚úÖ Daten sind gut strukturiert, ~3000 Spieler mit relevanten Features  
‚úÖ Zielvarinale (FDI) ist normalverteilt  
‚úÖ Starke bivariate Beziehungen erkannt (Durchschnitte, Checkout-Erfolg)  
‚ö†Ô∏è Massive Multikollinearit√§t (Features korrelieren zu 0.9+)  
‚ö†Ô∏è Starke geografische Effekte (Land-Dummies essentiell)  

---

## 2Ô∏è‚É£ NOTEBOOK: `notebooks/fdi_rating_modeling.ipynb`
### Modellentwicklung & Diagnose

**Ziel:** Machine-Learning-Modelle trainieren, die FDI-Rating vorhersagen, und verstehen, was funktioniert.

---

### Phase 1: Datenladen & Feature Engineering

#### Schritt 1: Data Leakage Prevention

**WAS:** Entfernen von `api_rank` und `api_overall_stat`.

**WARUM:** Diese Features sind DIREKT vom FDI-Rating abgeleitet oder sind das Ranking selbst!

**ANALOGE:** 
```
‚ùå FALSCH: "Vorhersagen Sie eine Pr√ºfungsnote" + "Geben Sie die L√∂sung vor"
‚úÖ RICHTIG: Vorhersagen Sie die Pr√ºfungsnote NUR basierend auf Studienzeit & Vorwissen
```

**KONSEQUENZ:** 
- Mit Data Leakage w√ºrde Modell 99% Genauigkeit zeigen, aber nur im Training
- In der Praxis (neue Spieler) w√ºrde es 0% Genauigkeit haben
- Wir entfernen beide Features SOFORT

**CODE:**
```python
LEAKY_FEATURES = ["api_rank", "api_overall_stat"]
df = df.drop(columns=LEAKY_FEATURES, errors="ignore")
```

---

#### Schritt 2: Feature Engineering (Neue Features aus Rohdaten)

**WAS:** 12 neue Features erstellen aus den bestehenden 37.

**WARUM:** Domain-Knowledge in Daten codieren ‚Üí Modell schneller lernen.

| Feature | Berechnung | Intuition |
|---------|-----------|-----------|
| `log_total_earnings` | log(earnings) | Logarithmieren wegen extrem rechtsschiefer Verteilung (Reiche Spieler sind Ausrei√üer) |
| `season_win_rate` | win_pct / 100 | Normalisiert von Prozent (0-100) zu Dezimal (0-1) |
| `checkout_combo` | (checkout% √ó double%) / 100 | Multiplikation: muss BEIDE F√§higkeiten haben |
| `first9_delta` | first9_avg - 12m_avg | Konsistenz-Check: starker Start oder nur sp√§ter gut? |
| `momentum_gap` | throw_avg - against_throw_avg | Psychologisches "Clutch": besser unter Druck oder nicht? |
| `experience_intensity` | tour_card_years / age | "Intensit√§t": wieviel des Lebens haben Darts gespielt? |
| `earnings_per_year` | total_earnings / tour_card_years | "Kapitaleffizienz": verdient pro Jahr aktiv |
| `first9_ratio` | first9_avg / 12m_avg | Prozentsatz: Start-Phase √úberdurchschnitt? |
| `break_efficiency` | legs_won_throwing2 / legs_won_throwing1 | "Breaking": besser gegnerische Aufschl√§ge brechenls halten? |
| `hold_break_spread` | legs_won_throw1 - legs_won_throw2 | Differenz: absoluter Unterschied Halten vs. Brechen |
| `power_scoring_ratio` | (180s + 171-180s) / (140s + 131-140s) | Hochpunkte vs. Standard-Punkte: aggressive oder konservativ? |
| `tv_stage_delta` | tv_avg - general_avg | Nervenst√§rke? H√∂her bei Kamera oder nicht? |

**BEISPIEL - Warum ist `first9_delta` wertvoll?**

Zwei Spieler mit gleicher 12-Monats-Average = 75:
```
Spieler A: First-9 = 85, Rest = 72  ‚Üí Delta = +13 (Starker Start, sp√§ter weniger)
Spieler B: First-9 = 65, Rest = 78  ‚Üí Delta = -13 (Schwacher Start, sp√§ter stark)
```

Ein lineares Modell k√∂nnte nicht den Unterschied erkennen (beide haben Average=75).
Mit `first9_delta` explizit: Der Unterschied wird dem Modell "geschenkt".

**ERGEBNIS:** 
- 37 urspr√ºngliche numerische Features
- 12 neue engineered Features
- Total: **38 Input-Features** f√ºr Modelle

---

#### Schritt 3: Featuresets Definieren

**WAS:** Gruppierung der Features nach Type.

```python
numeric_features = [
    # "Hard Facts" (direkt gemessen)
    "age", "last_12_months_averages", "last_12_months_checkout_pcnt",
    # ... weitere 35 numerische Features
]

categorical_features = ["country"]  # 30+ verschiedene L√§nder

# Total: 38 Features
```

#### Schritt 4: Train/Test-Split

**WAS:** 80% Training (1,981 Spieler), 20% Test (496 Spieler).

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```

**WARUM:** 
- Training: Modell "lernt" Muster
- Test: "Unbekannte" Spieler ‚Üí echte Vorhersage-Genauigkeit

**SEED (random_state=42):** Sorgt f√ºr **Reproduzierbarkeit** (gleiche Zahl ‚Üí gleicher Split immer).

---

### Phase 2: Baseline & Preprocessing

#### Baseline-Dummy-Modell

**WAS:** Einfachste m√∂gliche Vorhersage: "Sage immer den Durchschnitt des Training-Sets"

```python
baseline_value = y_train.mean()  # z.B. 1340
baseline_pred = [1340, 1340, 1340, ...]  # F√ºr alle Test-Spieler
```

**METRIKEN:**
```
R¬≤ = 0.0        (0% erkl√§rt)
RMSE = 188.7    (durchschnittlicher Fehler: 188.7 FDI-Punkte)
MAE = 151.1     (mittlerer absoluter Fehler: 151.1 Punkte)
```

**INTERPRETATION:** 
Alle echten Modelle m√ºssen BESSER als diese sein, sonst sind sie unn√∂tig.

---

#### Preprocessing Pipeline

**WAS:** 4 Schritte automatisiert:

```python
Pipeline([
    ('imputer', SimpleImputer(strategy='median')),    # Schritt 1: Fehlwerte f√ºllen
    ('scaler', StandardScaler()),                      # Schritt 2: Normalisieren
])
```

**SCHRITT 1: Imputation (Fehlwerte)**
- Numerisch: Median verwenden (robust gegen Ausrei√üer)
- Kategorisch: Mode (h√§ufigster Wert) verwenden
- Warum Median statt Mean? Median unempfindlich gegen Ausrei√üer

**SCHRITT 2: Skalierung**
- StandardScaler: (X - mean) / std
- Transformiert jedes Feature auf Mean=0, Std=1
- WARUM: Ridge/Lasso/KNN brauchen skalierte Features (sonst gro√üe Features dominieren)

**SCHRITT 3: Encoding (Kategorische Variablen)**
- One-Hot-Encoding: `country = "ENG"` ‚Üí `country_ENG=1, country_NED=0, ...`
- WARUM: ML-Modelle verstehen nur Zahlen, nicht Text

---

### Phase 3: Modelltraining & Vergleich

#### 4 verschiedene Modelle trainiert:

**1. LINEAR REGRESSION**
```
FDI = Œ≤‚ÇÄ + Œ≤‚ÇÅ√óage + Œ≤‚ÇÇ√óaverages + Œ≤‚ÇÉ√ócheckout% + ... + Œ≤‚ÇÉ‚Çà√ócountry
```
- Simplest, schnellste
- Aber: Annahme = lineare Beziehungen (stimmt nicht √ºberall)

**2. RIDGE REGRESSION (L2 Regularisierung)**
```
minimize: MSE(Y - ≈∂) + Œª √ó Œ£(Œ≤¬≤)
```
- Strafe f√ºr gro√üe Koeffizienten
- Stabilisiert bei Multikollinearit√§t
- Koeffizienten werden klein, aber nie exakt 0

**3. LASSO REGRESSION (L1 Regularisierung)**
```
minimize: MSE(Y - ≈∂) + Œª √ó Œ£|Œ≤|
```
- Aggressivere Strafe
- Setzt unwichtige Koeffizienten auf EXAKT 0
- = Automatische Feature-Selektion

**4. RANDOM FOREST (Tree Ensemble)**
```
FDI = Durchschnitt aus 600 Entscheidungsb√§umen
```
- Kann nonlineare Muster lernen
- Black-box (schwer interpretierbar)
- Robust gegen Multikollinearit√§t (B√§ume "ignorieren" Korrelationen)

---

#### ERGEBNISSE (Test-Metriken):

| Modell | R¬≤ | RMSE | MAE | Train-Test Gap | 
|--------|-----|------|-----|---|
| Baseline | 0.00 | 188.7 | 151.1 | - |
| Linear | 0.924 | 47.8 | 35.9 | 0.000 |
| Ridge (Œ±=5) | 0.929 | 45.8 | 34.4 | -0.001 |
| Lasso (Œ±=0.1) | 0.914 | 52.4 | 38.3 | 0.003 |
| **Random Forest** | **0.923** | **48.3** | **35.2** | **0.011** |

**INTERPRETATION:**

1. **Alle ML-Modelle > Baseline** ‚úÖ
   - Linear: 92.4% der Varianz erkl√§rt (vs. 0% Baseline) = HUGE Verbesserung!

2. **Ridge ist leicht besser als Linear** 
   - R¬≤: 0.929 vs 0.924 = nur +0.5% Verbesserung
   - Aber: Stabilere Koeffizienten wegen Multikollinearit√§t-Handling

3. **Lasso schlechter als Ridge**
   - Wahrscheinlich weil es zu viele Features auf 0 setzt (zu aggressiv)

4. **Random Forest vergleichbar mit Linear/Ridge**
   - Auch ~92% erkl√§rt
   - Train-Test Gap = 0.011 (akzeptabel, kein gro√ües Overfitting)
   - Nicht besser als Linear, aber auch nicht schlechter

**CHOICE:** Ridge oder Random Forest w√ºrden beide funktionieren. 
Wir werden **Random Forest w√§hlen** f√ºr GridSearchCV-Tuning.

---

### Phase 4: Hyperparameter-Tuning

#### GridSearchCV f√ºr Random Forest

**WAS:** Test ALLER Kombinationen von Hyperparameter-Optionen.

```python
param_grid = {
    'n_estimators': [300, 600],                # Anz. B√§ume
    'max_depth': [None, 10, 20],                # Baum-Tiefe
    'min_samples_leaf': [1, 2, 5],              # Min Beobachtungen pro Blatt
    'max_features': [0.5, 'sqrt', 'log2']      # Features pro Split
}
# 2 √ó 3 √ó 3 √ó 3 = 54 Kombinationen
# Mit 5-Fold CV = 270 Trainings-Durchl√§ufe
```

**BESTE PARAMETER GEFUNDEN:**
```
n_estimators = 600      (mittlere Anzahl)
max_depth = None        (keine Beschr√§nkung - B√§ume wachsen unbegrenzt)
min_samples_leaf = 2    (aggressiv splitten)
max_features = 0.5      (nutze nur 50% der Features pro Split)
```

**ERGEBNIS NACH TUNING:**
```
Test R¬≤ = 0.923 (vorher: 0.923)
Test RMSE = 48.3 (vorher: 48.3)
```

**FAZIT:** Tuning hat praktisch NICHTS verbessert! 
Das bedeutet: Standardparameter waren bereits gut.

---

### Phase 5: Multikollinearit√§t-Diagnose

#### VIF (Variance Inflation Factor) Berechnung

**WAS:** Misst, wie sehr Koeffizienten durch Multikollinearit√§t "aufgeblasen" werden.

```python
from statsmodels.stats.outliers_influence import variance_inflation_factor

for i, col in enumerate(numeric_features):
    vif = 1 / (1 - R¬≤_i)  # R¬≤ = wie gut kann Feature_i von anderen vorhergesagt werden?
```

**VIF-INTERPRETATION:**
```
VIF = 1.0   ‚Üí Kein Problem, unabh√§ngig
VIF = 5.0   ‚Üí Moderat problematisch (feature = 80% erkl√§rbar von anderen)
VIF = 10.0  ‚Üí Kritisch (90% erkl√§rbar)
VIF = 100+  ‚Üí Quasi perfekt redundant
```

**UNSER RESULTAT:**
```
‚úì VORHER (alle 37 numerischen Features):
  36 von 37 haben VIF > 5 (nur 1 Feature ist "clean")
  
‚úì NACHHER (nach Versuch der Reduktion):
  27 von 37 haben VIF > 5 (nur 10 Features sind "clean")
  
Top 5 problematische Features:
  - api_sum_field1: VIF = >1000 (perfekt redundant!)
  - last_12_months_averages: VIF = >1000
  - last_12_months_functional_doubles_pct: VIF = 500+
  - ... etc
```

**INTERPRETATION:**
- **Massive Multikollinearit√§t erkannt!**
- Features sind untereinander so stark korreliert, dass einzelne Koeffizienten unzuverl√§ssig sind
- Aber: F√ºr **Vorhersage** ist das weniger problematisch als f√ºr **Inferenz**
  - Ridge/Lasso/Random-Forest k√∂nnen damit umgehen
  - Nur lineare Regression's Koeffizienten werden instabil

---

#### Hochkorrelierte Feature-Paare

**WAS:** Alle Paare mit |r| > 0.8 identifiziert.

**BEISPIELE:**
```
r = 0.9999: last_12_months_averages ‚Üî api_sum_field1
r = 0.9999: last_12_months_functional_doubles_pct ‚Üî last_12_months_checkout_pcnt
r = 0.9903: last_12_months_with_throw ‚Üî last_12_months_first_9
```

**BEDEUTUNG:** r = 0.99 = wenn ich A kenne, kann ich B quasi exakt vorhersagen.
Features sind **praktisch identisch** ‚Üí eines ist redundant.

---

### Phase 6: Feature-Selektion via Lasso

#### Was Lasso tut

**WAS:** Trainiert ein lineares Modell MIT Strafe f√ºr gro√üe Koeffizienten.

```python
Lasso(alpha=0.01)  # Strafe: 0.01 √ó Œ£|Koeffizienten|
```

**EFFEKT:** Koeffizienten werden kleiner, und bei Œ± gro√ü genug, werden sie EXAKT 0.

#### ERGEBNIS

```
‚úÖ SELECTED FEATURES: 93 von 109 (85%)
   Top 5 nach |Koeffizient|:
   1. country_BOT (Botswana): 140.2  ‚Üê Botswana Spieler haben h√∂heres FDI!
   2. country_BRU (Brasilien): 124.8
   3. last_12_months_averages: 105.3 ‚Üê Aveeages sind wichtig
   4. country_CPV (Kap Verde): 94.2
   5. country_ISR (Israel): 88.5

‚ùå ELIMINATED FEATURES: 16 von 109 (15%)
   - hold_break_spread ‚Üí zu redundant
   - tv_stage_delta ‚Üí zu redundant
   - 13 country_dummies mit kleinen Populationen (z.B. country_ARM, country_BHR)
```

**INTERPRETATION:**

1. **Lasso konservativ** - eliminiert nur offensichtlich redundante Features
2. **Land-Dummies dominieren** - viele der Top-Koeffizienten sind countries
   - Best√§tigt unsere EDA-Findung: L√§nder sind wichtig!
3. **Eliminierte Features:**
   - `hold_break_spread`: Redundant zu `break_efficiency` (beide messen Halten vs. Brechen)
   - `tv_stage_delta`: Zu wenig Varianz oder redundant zu anderen Durchschnitten
   - Kleine L√§nder: Zu wenig Daten, starkes Overfitting-Risiko

---

## 3Ô∏è‚É£ NOTEBOOK: `reports/report.ipynb`
### Formaler Bericht

**Ziel:** Ergebnisse kompakt f√ºr Stakeholder zusammenfassen.

**Struktur:**

1. **Einf√ºhrung**: Was ist das Problem? Was ist FDI-Rating?
2. **Daten**: Woher kommen die Daten? Wieviele Spieler? Wieviele Features?
3. **Methodologie**: Welche Modelle? Welche Evaluations-Metriken?
4. **Ergebnisse**: Beste Modelle? Genauigkeit? Feature-Wichtigkeit?
5. **Schlussfolgerungen**: Was haben wir gelernt? Was sind Limitationen?
6. **Literatur**: Welche B√ºcher/Papers haben wir verwendet?

---

## 4Ô∏è‚É£ ZUS√ÑTZLICHE DATEIEN: `slides.md` & `README.md`
### Pr√§sentation & Dokumentation

**`slides.md`:** 8-Slide-Pr√§sentation f√ºr Google Slides/PowerPoint
**`README.md`:** Technische Dokumentation + Lessons Learned

---

## üìä ZUSAMMENFASSUNG: Welches Modell ist am besten?

| Modell | R¬≤ Test | RMSE | Interpretierbarkeit | Multikollinearit√§t-Robust | Wahl |
|--------|---------|------|------|-----|------|
| Linear | 0.924 | 47.8 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Einfach) | ‚ùå (VIF-Probleme) | Interpretierbar, aber instabil |
| Ridge | 0.929 | 45.8 | ‚≠ê‚≠ê‚≠ê‚≠ê (Moderat) | ‚úÖ Robust | **Best f√ºr Production** |
| Lasso | 0.914 | 52.4 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Sparse) | ‚úÖ Robust | Gut f√ºr Sparse-Daten |
| Random Forest | 0.923 | 48.3 | ‚≠ê‚≠ê‚≠ê (Black-box) | ‚úÖ Robust | Flexibel, aber hard to explain |

**EMPFEHLUNG:** **Ridge Regression** 
- H√∂chster R¬≤ (92.9%)
- Robust gegen Multikollinearit√§t
- Interpretierbar (Koeffizienten)
- Schnell & einfach zu deployen

---

## üéì KEY LEARNINGS

### 1. **Normalverteilung ist wichtig**
   - EDA zeigte: FDI ist (ann√§hernd) normalverteilt
   - Daher funktionieren lineare Modelle gut
   - Log-Transformation der Earnings war essentiell (sonst zu schief)

### 2. **Multikollinearit√§t != Katastrophe**
   - 36 von 37 Features haben VIF > 5 (massive Redundanz!)
   - Aber: Modelle funktionieren trotzdem gut (R¬≤ > 0.92)
   - Ridge/Lasso/RF-Modelle k√∂nnen damit umgehen
   - Problem ist nur f√ºr Linear-Regression's Koeffizienten (werden instabil)

### 3. **Feature Engineering zahlt sich aus**
   - 12 neue Features aus Domain-Knowledge generiert
   - Features wie `first9_delta`, `break_efficiency` sind interpretierbar
   - Modell brauchte das Wissen nicht zu "erfinden"

### 4. **Geografische Effekte sind real**
   - Chi-Quadrat-Tests zeigen: L√§nder beeinflussen FDI & Checkout-Erfolg signifikant
   - England/Niederlande haben 35% der Top 25% Spieler (vs. 25% erwartet)
   - Deutschland √ºberraschend schwach (Sampling-Bias oder echte Unterschiede?)

### 5. **Data Leakage is critical**
   - `api_rank` und `api_overall_stat` M√úSSEN entfernt werden
   - W√ºrden unrealistisch hohe Genauigkeit vort√§uschen
   - Echte Vorhersagen brauchen nur "echte" Features

### 6. **Random Forest bringt keine Verbesserung**
   - "Intelligentere" Modelle sind nicht automatisch besser
   - RF: R¬≤ = 0.923, Linear: R¬≤ = 0.924 ‚Üí praktisch identisch
   - Aber: RF ist robuster gegen Annahmen, Linear ist interpretierbar
   - **Trade-off:** Einfachheit vs. Flexibilit√§t

---

## üöÄ NEXT STEPS (Wenn Zeit/Ressourcen vorhanden)

1. **Feature Importance Analysis (Random Forest):**
   - Welche 5 Features sind AM WICHTIGSTEN?
   - K√∂nnten wir mit 5-10 Features 85% Genauigkeit erreichen?

2. **Residual Analysis:**
   - Wo macht das Modell Fehler?
   - Gibt es systematische Fehler (z.B. √ºbersch√§tzt neue Spieler)?

3. **Ensemble Methods:**
   - Kombinieren Sie Ridge + Random Forest
   - Weighted Average der Vorhersagen k√∂nnte besser sein

4. **Cross-Validation Stability:**
   - TimeSeriesSplit statt Random Split?
   - Wie stabil sind Modelle wenn wir Daten zeitlich trennen?

5. **Deployment:**
   - API bauen (FastAPI/Flask)
   - Gradio App (bereits vorhanden) mit beste Modell verbinden
   - Docker-Container f√ºr Skalierbarkeit

---

## üìö Referenzen

- **OpenIntro: Introduction to Modern Statistics** (2e) - Methodologie f√ºr EDA
- **ISLP: An Introduction to Statistical Learning with Python** (James et al. 2023) - Regularisierung, Modellselection
- **sklearn Dokumentation** - Implementierungen

---

**Notebook-Autor:** Simon  
**Projekt:** FDI Analytics Pipeline  
**Datum:** 2026
