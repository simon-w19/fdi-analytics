# ğŸ¯ FDI Analytics

> **End-to-End Darts Analytics: PrÃ¤diktive Modellierung des FDI-Ratings mittels einer containerisierten Data-Pipeline**

[![Python 3.12](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://docs.docker.com/compose/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Dieses Projekt prognostiziert das **FDI-Rating** (Future Dart Intelligence) professioneller Darts-Spieler mithilfe statistischer Modelle. Die vollstÃ¤ndige Pipeline â€“ von Web-Scraping Ã¼ber Feature Engineering bis zum Deployment â€“ lÃ¤uft containerisiert.

---

## ğŸ“‹ Inhaltsverzeichnis

- [Features](#-features)
- [Quick Start](#-quick-start)
- [Architektur](#-architektur)
- [Projektstruktur](#-projektstruktur)
- [Datenpipeline](#-datenpipeline)
- [Modellierung](#-modellierung)
- [KPIs & Ergebnisse](#-kpis--ergebnisse)
- [Konfiguration](#-konfiguration)
- [Entwicklung](#-entwicklung)
- [Lessons Learned](#-lessons-learned)
- [Lizenz](#-lizenz)

---

## âœ¨ Features

- **ğŸ•·ï¸ Automatisiertes Web-Scraping** von [DartsOrakel](https://dartsorakel.com)
- **ğŸ”„ ETL-Pipeline** mit Feature Engineering und PostgreSQL-Integration
- **ğŸ“Š Modellvergleich**: Linear Regression und Lasso mit GridSearchCV
- **ğŸŒ Gradio Web-App** fÃ¼r Echtzeit-Vorhersagen
- **ğŸ³ VollstÃ¤ndig containerisiert** mit Docker Compose
- **â° Automatische Updates** via Scheduler (wÃ¶chentlich konfigurierbar)

---

## ğŸš€ Quick Start

### Voraussetzungen

- [Docker](https://docs.docker.com/get-docker/) & Docker Compose
- [uv](https://github.com/astral-sh/uv) (Python Package Manager) fÃ¼r lokale Entwicklung

### Installation

```bash
# Repository klonen
git clone https://github.com/yourusername/fdi-analytics.git
cd fdi-analytics

# Umgebungsvariablen konfigurieren
cp .env.example .env

# Container starten (baut Images, fÃ¼hrt ETL aus, startet App)
docker compose up -d
```

### Zugriff

| Endpunkt | URL |
|----------|-----|
| **Web-App** | http://localhost:7860 |
| **API Health** | http://localhost:7860/api/health |
| **API Predict** | http://localhost:7860/api/predict |

---

## ğŸ—ï¸ Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scraper   â”‚â”€â”€â”€â”€â–¶â”‚  Transform  â”‚â”€â”€â”€â”€â–¶â”‚  PostgreSQL â”‚
â”‚ (Beautiful  â”‚     â”‚  (Feature   â”‚     â”‚    (DB)     â”‚
â”‚    Soup)    â”‚     â”‚ Engineering)â”‚     â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   Gradio    â”‚â—€â”€â”€â”€â”€â”‚   Train     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   Web-App   â”‚     â”‚  (sklearn)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Docker Services

| Service | Beschreibung | Port |
|---------|--------------|------|
| `db` | PostgreSQL 16 (Alpine) mit persistentem Volume | 5432 |
| `etl` | Scraping â†’ Transform â†’ Train â†’ Ingest | - |
| `scheduler` | Periodisches ETL-Refresh | - |
| `app` | Gradio + FastAPI Web-Service | 7860 |

---

## ğŸ“ Projektstruktur

```
fdi-analytics/
â”œâ”€â”€ app/                    # Gradio + FastAPI Web-Service
â”‚   â””â”€â”€ gradio_app.py       # Prediction Studio & Insights
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Scraper-Output (CSV)
â”‚   â””â”€â”€ processed/          # Feature-engineerte Daten
â”œâ”€â”€ docker/                 # Dockerfiles
â”œâ”€â”€ models/                 # Trainierte Modelle (.joblib)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda.ipynb           # Explorative Datenanalyse
â”‚   â””â”€â”€ fdi_rating_modeling.ipynb  # Modellierung & Evaluation
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ scraper.py          # BeautifulSoup Web-Scraper
â”‚   â”œâ”€â”€ transform.py        # Feature Engineering
â”‚   â”œâ”€â”€ features.py         # Feature-Definitionen
â”‚   â”œâ”€â”€ train.py            # Modelltraining & Vergleich
â”‚   â”œâ”€â”€ ingest.py           # PostgreSQL-Import
â”‚   â”œâ”€â”€ etl.py              # Pipeline-Orchestrierung
â”‚   â””â”€â”€ scheduler.py        # Cron-Ã¤hnlicher Loop
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ metrics/            # Modell-Metriken (JSON)
â”œâ”€â”€ tests/                  # Pytest-Suite
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ pyproject.toml
```

---

## ğŸ”„ Datenpipeline

### VollstÃ¤ndiger ETL-Lauf

```bash
# Lokal (mit uv)
uv run python -m pipeline.etl

# Mit Optionen
uv run python -m pipeline.etl --max-players 100 --skip-train
```

### Einzelne Schritte

```bash
# Nur Scraping
uv run python -m pipeline.scraper --max-players 50 --output data/raw/test.csv

# Nur Training
uv run python -m pipeline.train --csv data/processed/player_stats_all.csv

# App starten (lokal)
uv run python -m app.gradio_app
```

### Docker-Workflow

```bash
# Alles neu bauen und starten
docker compose down && docker compose build --no-cache && docker compose up -d

# ETL manuell triggern
docker compose run --rm etl

# Logs verfolgen
docker compose logs -f etl
```

---

## ğŸ“ˆ Modellierung

### Verglichene Modelle

| Modell | RÂ² | MAE | RMSE |
|--------|-----|-----|------|
| Linear Regression | 0.928 | 35.4 | 46.4 |
| **Lasso (Î±=0.01)** | **0.928** | **35.4** | **46.2** |

### Feature Engineering

**Numerische Features** (38 total):
- **Performance**: 3-Dart Average, First-9 Average, Checkout %
- **Erfolg**: Season Win Rate, Legs Won %, Order of Merit
- **Finanzen**: Log-transformierte Earnings
- **Abgeleitete**: `first9_delta`, `momentum_gap`, `break_efficiency`, `power_scoring_ratio`

**Kategorisch**: Country (One-Hot Encoded, ~30 LÃ¤nder)

### Top-5 PrÃ¤diktoren

1. **last_12_months_first_9_averages** â€“ Early-Game-Dominanz
2. **last_12_months_checkout_pcnt** â€“ Finish-QualitÃ¤t
3. **last_12_months_pcnt_legs_won** â€“ Gewinneffizienz
4. **log_total_earnings** â€“ Langfristiger Erfolg
5. **profile_season_win_pct** â€“ Aktuelle Form

---

## ğŸ¯ Ergebnisse

| KPI | Wert |
|-----|------|
| Modellgenauigkeit (MAE) | 35.4 FDI-Punkte |
| ErklÃ¤rte Varianz (RÂ²) | 0.928 |
| Production Readiness | Docker + <100ms Inference |

---

## âš™ï¸ Konfiguration

### Wichtige Umgebungsvariablen

| Variable | Beschreibung | Default |
|----------|--------------|---------|
| `FDI_SKIP_SCRAPE` | Scraping Ã¼berspringen | `false` |
| `FDI_SKIP_TRAIN` | Training Ã¼berspringen | `false` |
| `FDI_SCRAPE_MAX_PLAYERS` | Spieler-Limit (leer = alle) | - |
| `FDI_SCRAPE_DELAY_SECONDS` | Delay zwischen Requests | `0` |
| `FDI_REFRESH_MINUTES` | Scheduler-Intervall | `10080` (7 Tage) |
| `APP_PORT` | Gradio-Port | `7860` |
| `DATABASE_URL` | PostgreSQL-Connection | siehe `.env` |

VollstÃ¤ndige Liste: siehe [.env.example](.env.example)

---

## ğŸ› ï¸ Entwicklung

### Setup

```bash
# Dependencies installieren
uv sync

# Tests ausfÃ¼hren
uv run pytest

# Linting
uv run ruff check .

# Formatierung
uv run ruff format .
```

### Modell-Artefakte aktualisieren

```bash
# Training lokal ausfÃ¼hren
uv run python -m pipeline.train

# Container neu starten (lÃ¤dt neues Modell)
docker compose restart app
```

---

## ğŸ’¡ Lessons Learned

1. **Log-Transformation**: Earnings sind stark rechtsschief â€“ ohne Log dominieren AusreiÃŸer
2. **Regularisierung**: Lasso reduziert Ãœberanpassung und selektiert automatisch Features
3. **Data Leakage vermeiden**: API-Rankings (`api_rank`) korrelieren perfekt mit Target â†’ entfernt
4. **Feature Engineering**: Abgeleitete Features wie `first9_delta` verbessern Interpretierbarkeit

---

## ğŸ“š Referenzen

- [Introduction to Modern Statistics](https://openintro-ims.netlify.app/) â€“ OpenIntro
- [DartsOrakel](https://dartsorakel.com) â€“ Datenquelle

---

## ğŸ“„ Lizenz

MIT License â€“ siehe [LICENSE](LICENSE)

---

<p align="center">
  <i>Entwickelt fÃ¼r das Modul "Data Analytics with Statistics" an der HdM Stuttgart</i>
</p>
